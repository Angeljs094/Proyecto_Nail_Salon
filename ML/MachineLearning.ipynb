{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importacion de librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#para el modelo\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apertura de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelp\n",
    "businessy = pd.read_csv('Cleaned_Business_Y.csv')\n",
    "businessry = pd.read_csv('Cleaned_Review_Y.csv')\n",
    "usery = pd.read_csv('Cleaned_User_Y.csv')\n",
    "usery = usery.drop_duplicates(subset=['user_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision de Archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessry.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessry.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usery.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usery.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de Categorias para el modelo\n",
    "\n",
    "Se crean varias categorias del analisis del texto de los comentarios, para entrenar el modelo de machine learning con mayor informacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion categoria **interaccion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usery = pd.read_csv('Cleaned_User_Y.csv')\n",
    "usery = usery.drop_duplicates(subset=['user_id'])\n",
    "#Crea la categoria interaccion de la suma de columnas de varias colunmas de interaccion entre el numero de comentarios por usuario\n",
    "usery['interaccion'] = ( usery['useful'] + usery['funny']\t+ usery['cool'] + usery['compliment_hot'] + usery['compliment_more'] + usery['compliment_profile'] + usery['compliment_cute']\t+ usery['compliment_list']\t+ usery['compliment_note']\t+ usery['compliment_plain']\t+ usery['compliment_cool']\t+ usery['compliment_funny']\t+ usery['compliment_writer']\t+ usery['compliment_photos'] )/ usery['review_count']\n",
    "\n",
    "\n",
    "#Creacion de la categoria binaria \n",
    "#valor de la mediana\n",
    "mediana_interaccion = usery['interaccion'].median()\n",
    "#Se inicializa la columna con el valor 0\n",
    "usery['cat_interaccion'] = 0 \n",
    "#Agrega 1 a la nueva columna cuando interaccion es mayor que su mediana\n",
    "usery.loc[usery['interaccion'] > mediana_interaccion*(4/5), 'cat_interaccion'] = 1\n",
    "#borra la columna interaccion\n",
    "usery.drop(columns={'interaccion'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion categoria **elite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de palabras para la categoria elite\n",
    "lista_palabras = [\"great experience\",  \"great\",  \"happy\",  \"trust\",  \"designs\",  \"exactly what i wanted\", \"exactly\", \"wanted\", \"extremely talented\", \"talented\",\n",
    "\"amazing work\", \" amazing\", \"immediatel\", \"extremely nice\", \"nice\", \"very precisely\", \"precisely\", \"fastest\", \"spacious salon\", \"spacious\", \"wine\", \"chocolate\",\n",
    "\"soda\", \"friendly\", \"fantastic stylist\", \"fantastic\", \"great pedicurist\", \"great pedicure\", \"perfect\", \"absolutely amazing\", \"amazing\",\"highly recommend\",\n",
    "\"very clean\", \"clean\", \"very relaxing\", \"relaxing\", \"thank\", \"great experience\", \"was awesome\", \"awesome\", \"unique\", \"place unique\", \"great\", \"customer\", \"service\"\n",
    "\"luxurious\", \"luxury\", \"spa\", \"spas\", \"genuinely\", \"helpful\", \"sweet\", \"love\", \"loved\", \"talented\", \"excellent\", \"best\", \"originally\", \"original\", \"Organized\" ]\n",
    "\n",
    "#pasa las palabras de la lista a minusculas\n",
    "lista_palabras = [palabra.lower() for palabra in lista_palabras]\n",
    "\n",
    "#Hace la comparacion de cada palabara de la lista en los textos de los comentarios,\n",
    "#cuenta cuantas veces aparece una palabra de la lista por comentario, se guarda en una lista y se agrega al daraframe\n",
    "lista=[]\n",
    "for l in range(0,len(businessry)):\n",
    "    count = 0\n",
    "    for i,k in enumerate(lista_palabras):\n",
    "\n",
    "         if k in list(businessry['text'].iloc[l].lower().replace(',','').replace('.','').split()):\n",
    "            count =+1\n",
    "    lista.append(count)   \n",
    "businessry['elite'] = pd.DataFrame(lista)        \n",
    "\n",
    "#crea la columna final cat_elite\n",
    "businessry['cat_elite'] = 0 \n",
    "#Agrega 1 a la nueva columna cuando limpieza es mayor que 1\n",
    "businessry.loc[businessry['elite'] >= 1, 'cat_elite'] = 1\n",
    "#borra la columna limpieza\n",
    "businessry.drop(columns={'elite'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de categoria **limpieza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de palabras para la categoria Limpieza\n",
    "lista_palabras = [\"Cleanliness\", \"Sanitary\", \"Hygienic\", \"Organized\", \"Tidy\", \"Neat\", \"Sterile\", \"Spotless\", \"Immaculate\", \"Orderly\",\"Clean\",\n",
    "\"Well maintained\", \"Squeaky clean\", \"Clutter free\", \"Pristine\", \"Fresh\", \"Spacious\", \"Meticulous\", \"Well groomed\",\"Freshly\",\n",
    "\"Well kept\", \"Structured\", \"Efficient\", \"Methodical\", \"Systematic\", \"Arranged\", \"Presentable\", \"Gleaming\", \"Polished\",\n",
    "\"Crystalline\", \"Aseptic\", \"Uncluttered\", \"Sleek\", \"Trim\", \"Groomed\", \"Hygienized\", \"Disinfected\", \"Tended\", \"Spartan\",\n",
    "\"Trimmed\", \"Kempt\", \"Slick\", \"Unblemished\", \"Clear\", \"Unsoiled\", \"Unspoiled\", \"Unblemished\", \"Aseptic\", \"Trimmed\", \"Shining\"]\n",
    "\n",
    "#pasa las palabras de la lista a minusculas\n",
    "lista_palabras = [palabra.lower() for palabra in lista_palabras]\n",
    "\n",
    "#Hace la comparacion de cada palabara de la lista en los textos de los comentarios,\n",
    "#cuenta cuantas veces aparece una palabra de la lista por comentario, se guarda en una lista y se agrega al daraframe\n",
    "lista=[]\n",
    "for l in range(0,len(businessry)):\n",
    "    count = 0\n",
    "    for i,k in enumerate(lista_palabras):\n",
    "\n",
    "         if k in list(businessry['text'].iloc[l].lower().replace(',','').replace('.','').split()):\n",
    "            count =+1\n",
    "    lista.append(count)   \n",
    "businessry['limpieza'] = pd.DataFrame(lista)        \n",
    "\n",
    "#crea la columna final cat_limpieza\n",
    "businessry['cat_limpieza'] = 0 \n",
    "#Agrega 1 a la nueva columna cuando limpieza es mayor que 1\n",
    "businessry.loc[businessry['limpieza'] >= 1, 'cat_limpieza'] = 1\n",
    "#borra la columna limpieza\n",
    "businessry.drop(columns={'limpieza'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion categoria **ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de palabras para la categoria Limpieza\n",
    "lista_palabras = [\"Courteous\", \"Polite\", \"Friendly\", \"Welcoming\", \"Attentive\", \"Respectful\", \"Helpful\", \"Warm\", \"Cordial\",\n",
    "\"Approachable\", \"Customer focused\", \"Personable\", \"Service oriented\", \"Professional\", \"Amiable\", \"Cheerful\",\n",
    "\"Considerate\", \"Kind\", \"Patient\", \"Understanding\", \"Responsive\", \"Empathetic\", \"Courageous\", \"Generous\",\n",
    "\"Gracious\", \"Grateful\", \"Hospitable\", \"Inviting\", \"Gratifying\", \"Pleasant\", \"Thoughtful\", \"Customer centric\",\n",
    "\"Gratifying\", \"Obliging\", \"Sociable\", \"Affable\", \"Gentle\", \"Good humored\", \"Grateful\", \"Amicable\", \"Engaging\",\n",
    "\"Enthusiastic\", \"Good-natured\", \"Grateful\", \"Sociable\", \"Amicable\", \"Charming\", \"Compassionate\", \"Cooperative\"]\n",
    "\n",
    "\n",
    "#pasa las palabras de la lista a minusculas\n",
    "lista_palabras = [palabra.lower() for palabra in lista_palabras]\n",
    "\n",
    "#Hace la comparacion de cada palabara de la lista en los textos de los comentarios,\n",
    "#cuenta cuantas veces aparece una palabra de la lista por comentario, se guarda en una lista y se agrega al daraframe\n",
    "lista=[]\n",
    "for l in range(0,len(businessry)):\n",
    "    count = 0\n",
    "    for i,k in enumerate(lista_palabras):\n",
    "\n",
    "         if k in list(businessry['text'].iloc[l].lower().replace(',','').replace('.','').split()):\n",
    "            count =+1\n",
    "    lista.append(count)   \n",
    "businessry['ambiente'] = pd.DataFrame(lista)        \n",
    "\n",
    "#crea la columna final cat_limpieza\n",
    "businessry['cat_ambiente'] = 0 \n",
    "#Agrega 1 a la nueva columna cuando limpieza es mayor que 1\n",
    "businessry.loc[businessry['ambiente'] >= 1, 'cat_ambiente'] = 1\n",
    "#borra la columna ambiente\n",
    "businessry.drop(columns={'ambiente'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion categoria **promociones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de palabras para la categoria Limpieza\n",
    "lista_palabras = [\"Affordable\", \"Reasonable\", \"Competitive\", \"Budget friendly\", \"Cost effective\", \"Economical\", \"Inexpensive\",\n",
    "\"Attractive pricing\", \"Value for money\", \"Discounted\", \"Special offers\", \"Savings\", \"Cost efficient\",\n",
    "\"Reasonably priced\", \"Economically priced\", \"Low cost\", \"Wallet friendly\", \"Bargain\", \"Discounts\",\n",
    "\"Promotional prices\", \"Saver deals\", \"Reduced rates\", \"Money saving\", \"Affordable rates\",\"low\",\"cost\" \n",
    "\"Economically priced\", \"Discounted offers\", \"Competitive prices\", \"Pocket friendly\", \"Inexpensive deals\",\n",
    "\"Affordable options\", \"Sale\", \"Cut rate\", \"Low priced\", \"Thrifty\", \"Reasonably valued\", \"Marked down\",\n",
    "\"On\", \"sale\", \"Cost conscious\", \"Attractive discounts\", \"Economical choices\", \"Savings opportunities\",\n",
    "\"Discounted packages\", \"Special promotions\", \"Budget conscious\", \"Discounted rates\", \"Affordable packages\",\n",
    "\"Promo\", \"Reduced cost\", \"Economic options\", \"Money saving deals\", \"Discounted specials\"]\n",
    "\n",
    "\n",
    "#pasa las palabras de la lista a minusculas\n",
    "lista_palabras = [palabra.lower() for palabra in lista_palabras]\n",
    "\n",
    "#Hace la comparacion de cada palabara de la lista en los textos de los comentarios,\n",
    "#cuenta cuantas veces aparece una palabra de la lista por comentario, se guarda en una lista y se agrega al daraframe\n",
    "lista=[]\n",
    "for l in range(0,len(businessry)):\n",
    "    count = 0\n",
    "    for i,k in enumerate(lista_palabras):\n",
    "\n",
    "         if k in list(businessry['text'].iloc[l].lower().replace(',','').replace('.','').split()):\n",
    "            count =+1\n",
    "    lista.append(count)   \n",
    "businessry['promociones'] = pd.DataFrame(lista)        \n",
    "\n",
    "#crea la columna final cat_limpieza\n",
    "businessry['cat_promociones'] = 0 \n",
    "#Agrega 1 a la nueva columna cuando limpieza es mayor que 1\n",
    "businessry.loc[businessry['promociones'] >= 1, 'cat_promociones'] = 1\n",
    "#borra la columna promociones\n",
    "businessry.drop(columns={'promociones'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion categoria extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista de palabras para la categoria extra\n",
    "lista_palabras = [\"Haircut\", \"Hairstyling\", \"coloring\", \"Highlights\", \"Lowlights\", \"Balayage\", \"Ombre\", \"extensions\",\n",
    " \"straightening\", \"perm\", \"Keratin\", \"smoothing\", \"Blowout\", \"Updo\", \"Braiding\", \"braids\", \"hairstyles\", \"Men\", \"Women\", \n",
    " \"Children\", \"haircut\",\"Pixie\", \"Bob\", \"Shag\", \"Bangs\", \"Curls\", \"Curly\", \"conditioning\", \"massage\", \"Deep\", \"repair\", \n",
    " \"glossing\", \"glazing\", \"treatment\", \"spa\", \"rejuvenation\", \"health\", \"consultation\", \"care\" ,\"tips\", \"hydration\", \"oil\", \"mask\", \n",
    "\"trimming\", \"shaping\", \"Beard\", \"grooming\", \"Mustache\",  \"Children's hair styling\", \"Bridal hair styling\", \"consultation\", \"wine\",\n",
    "\"hair\", \"spa\" \"Manicure\", \"Pedicure\", \"Acrylic\", \"Gel\", \"extensions\", \"art\", \"design\", \"French\",\"Shellac\", \"SNS\", \"Dip\" ,\n",
    "\"powder\", \"repair\", \"removal\", \"shaping\", \"Cuticle\", \"care\",\"Paraffin\", \"wax\", \"strengthening\", \"Nails\", \"polish\",\n",
    "\"buffing\", \"Foot\",\" massage\", \"Hand\", \"Callus\",\" removal\", \"scrub\", \"Moisturizing\" , \"Hot oil treatment\", \"Nail spa\", \n",
    "\"Nail rejuvenation\", \"Nail health consultation\", \"Nail care tips\", \"Nail conditioning\", \"hydration\", \n",
    "\"Cuticle oil\", \"Nail mask\", \"Gel removal\", \"filing\", \"varnish\", \"Chrome\", \"Ombre\",\n",
    "\"Matte\", \"Glitter\", \"Natural\", \"Quick dry options\", \"wraps\", \"parking\",\n",
    "\"embellishments\", \"gems\", \"decals\", \"stickers\", \"color\" ,\"options\", \"Signature\"]\n",
    "\n",
    "\n",
    "\n",
    "#pasa las palabras de la lista a minusculas\n",
    "lista_palabras = [palabra.lower() for palabra in lista_palabras]\n",
    "\n",
    "#Hace la comparacion de cada palabara de la lista en los textos de los comentarios,\n",
    "#cuenta cuantas veces aparece una palabra de la lista por comentario, se guarda en una lista y se agrega al daraframe\n",
    "lista=[]\n",
    "for l in range(0,len(businessry)):\n",
    "    count = 0\n",
    "    for i,k in enumerate(lista_palabras):\n",
    "\n",
    "         if k in list(businessry['text'].iloc[l].lower().replace(',','').replace('.','').split()):\n",
    "            count =+1\n",
    "    lista.append(count)   \n",
    "businessry['extra'] = pd.DataFrame(lista)        \n",
    "\n",
    "#crea la columna final cat_limpieza\n",
    "businessry['cat_extra'] = 0 \n",
    "#Agrega 1 a la nueva columna cuando limpieza es mayor que 1\n",
    "businessry.loc[businessry['extra'] >= 1, 'cat_extra'] = 1\n",
    "#borra la columna extra\n",
    "businessry.drop(columns={'extra'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion Dataframe para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessry.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = businessry[['user_id', 'business_id', 'review_stars', 'text', 'date', 'year',\n",
    "       'source', 'cat_elite', 'cat_limpieza', 'cat_ambiente',\n",
    "       'cat_promociones', 'cat_extra']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usery.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=df.merge(usery, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop([ 'text', 'date', 'year',\n",
    "       'source', 'name', 'review_count', 'yelping_since',\n",
    "       'useful', 'funny', 'cool', 'elite', 'friends', 'fans', 'average_stars',\n",
    "       'compliment_hot', 'compliment_more', 'compliment_profile',\n",
    "       'compliment_cute', 'compliment_list', 'compliment_note',\n",
    "       'compliment_plain', 'compliment_cool', 'compliment_funny',\n",
    "       'compliment_writer', 'compliment_photos'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df_ml.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion Modelo business_id - business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = pd.read_csv('df_ml.csv')\n",
    "df_ml.drop([ 'user_id'], axis=1, inplace=True)\n",
    "#se quita los duplicados, pero deberia traerlo ya listo\n",
    "df_ml=df_ml.drop_duplicates(subset=['business_id'])\n",
    "\n",
    "businessy = pd.read_csv('Cleaned_Business_Y.csv')\n",
    "\n",
    "df_modelo = df_ml[[ 'cat_elite',\t'cat_limpieza',\t'cat_ambiente',\t'cat_promociones',\t'cat_extra',\t'cat_interaccion']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(df_modelo, df_modelo)\n",
    "#print(f\"Dimensiones de la matriz: {cosine_sim.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para hacer la recomendacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Entrada (nombre de negocio:str,Numero de recomendaciones a devolver:int)\n",
    "Salida (lista con los nombres de negocios recomendados )\n",
    "\n",
    "'''\n",
    "\n",
    "def get_recomendation(nombre, numero_recomendaciones):\n",
    " id=businessy[businessy['name']==nombre].iloc[0][0]\n",
    " indice = df_ml.index[df_ml['business_id'] == id].tolist()\n",
    " sim_scores = list(enumerate(cosine_sim[indice[0]]))\n",
    " sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    " sim_scores = sim_scores[1:numero_recomendaciones+2]\n",
    " similar_id = [i[0] for i in sim_scores]\n",
    "\n",
    " lista=[]\n",
    " \n",
    " #Revisar bien al usar el codigo final, porque los diccionarios no guardan orden\n",
    " for i,k in enumerate(range(0,len(similar_id))):\n",
    "    if businessy[businessy['business_id']==df_ml.iloc[i][0]].iloc[0][1] != nombre:\n",
    "\n",
    "       lista.append(  {  'Nombre Local' : businessy[businessy['business_id']==df_ml.iloc[i][0]].iloc[0][1], \n",
    "                       'Direccion' : businessy[businessy['business_id']==df_ml.iloc[i][0]].iloc[0][2]  }  )\n",
    "\n",
    "       dic1 = {'Locales Recomendados': lista, }\n",
    "\n",
    "\n",
    "    \n",
    " return lista  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba de modelo - business_id-business_id <br>  Nombres:\n",
    "'Heaven Nails & Spa'\n",
    "'Nails & Beauty Lounge'\n",
    "'Future Nails'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Nombre Local': 'Future Nails', 'Direccion': '6162 Gunn Hwy'},\n",
       " {'Nombre Local': 'Nails & Beauty Lounge', 'Direccion': '953 E Brandon Blvd'},\n",
       " {'Nombre Local': \"Alyssa's Salon\", 'Direccion': '7330 Gulf Blvd'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recomendation('Glossy 130 Nails & Spa',3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de Modelo user_id - business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = pd.read_csv('df_ml.csv')\n",
    "df_ml = df_ml.drop_duplicates(subset=['user_id'])\n",
    "df_ml = df_ml.drop_duplicates()\n",
    "\n",
    "df_modelo=df_ml[['user_id', 'business_id', 'review_stars']]\n",
    "#df_modelo = df_modelo['review_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6Mhbp06FEhD9uxUGCCUmKA</td>\n",
       "      <td>fBNjTSdPJ1mtTzIHYpQnDw</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-FFgJuDZLmcZtrxDTRC7sg</td>\n",
       "      <td>my0bmPD5dgDFE1ia__LNlw</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g34LsuGf9gj9h5wqhye-Jw</td>\n",
       "      <td>bP8Y5cHMda64Z3tGA-cYzw</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HPTlXpHuvS57z2ZddDZ1qw</td>\n",
       "      <td>pSFiOUTMtyoSBpZ_T13rUA</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EavRoE6lTQi4CECEqhvxaA</td>\n",
       "      <td>bP8Y5cHMda64Z3tGA-cYzw</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  review_stars\n",
       "0  6Mhbp06FEhD9uxUGCCUmKA  fBNjTSdPJ1mtTzIHYpQnDw           1.0\n",
       "1  -FFgJuDZLmcZtrxDTRC7sg  my0bmPD5dgDFE1ia__LNlw           5.0\n",
       "2  g34LsuGf9gj9h5wqhye-Jw  bP8Y5cHMda64Z3tGA-cYzw           5.0\n",
       "3  HPTlXpHuvS57z2ZddDZ1qw  pSFiOUTMtyoSBpZ_T13rUA           5.0\n",
       "4  EavRoE6lTQi4CECEqhvxaA  bP8Y5cHMda64Z3tGA-cYzw           5.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba modelo user-user business-business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_usuario_elemento = df_modelo.pivot_table(index='user_id', columns='business_id', values='review_stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_usuario_elemento = matriz_usuario_elemento.fillna(matriz_usuario_elemento.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la similitud de cosenos entre usuarios\n",
    "similitud_usuarios = cosine_similarity(matriz_usuario_elemento)\n",
    "\n",
    "# Calcula la similitud de cosenos entre negocios\n",
    "similitud_negocios = cosine_similarity(matriz_usuario_elemento.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '6Mhbp06FEhD9uxUGCCUmKA'  # Reemplaza 'usuario_especifico' con el ID del usuario que deseas recomendar\n",
    "indice_usuario = df.index[df['user_id'] == user_id].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_similares = similitud_usuarios[indice_usuario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_similitud = 0.9\n",
    "usuarios_ordenados = sorted(list(enumerate(usuarios_similares)), key=lambda x: x[1], reverse=True)\n",
    "usuarios_ordenados = usuarios_ordenados[1:10+1]\n",
    "\n",
    "usuarios_similares_significativos = [index for index, similitud in usuarios_ordenados if similitud > umbral_similitud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negocios_recomendados = set()\n",
    "\n",
    "for usuario_similar in usuarios_similares_significativos:\n",
    "    negocios_recomendados.update(matriz_usuario_elemento.iloc[usuario_similar].dropna().index)\n",
    "\n",
    "negocios_recomendados = list(negocios_recomendados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recomendaciones para el usuario {user_id}: {negocios_recomendados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo user_id - business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "df_ml = pd.read_csv('df_ml.csv')\n",
    "df_ml.drop(columns=['cat_elite',\t'cat_limpieza',\t'cat_ambiente',\t'cat_promociones',\t'cat_extra',\t'cat_interaccion'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = train_test_split(df_ml, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configurar la matriz de usuario-negocio\n",
    "user_item_matrix = train_data.pivot_table(index='user_id', columns='business_id', values='review_stars', fill_value=0)\n",
    "\n",
    "# Configurar el modelo KNN\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(user_item_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id='6Mhbp06FEhD9uxUGCCUmKA'\n",
    "user_ratings = user_item_matrix.iloc[0].values.reshape(1, -1)\n",
    "user_ratings\n",
    "distances, indices = knn_model.kneighbors(user_ratings, n_neighbors=5 + 1)\n",
    "print(indices)\n",
    "recommendations = []\n",
    "for i in range(1, len(distances.flatten())):\n",
    "        business_id = user_item_matrix.columns[indices.flatten()[i]]\n",
    "        recommendations.append(business_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener recomendaciones para un usuario dado\n",
    "def get_recommendations(user_id, k=5):\n",
    "    user_ratings = user_item_matrix.loc[user_id].values.reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(user_ratings, n_neighbors=k + 1)\n",
    "    recommendations = []\n",
    "    for i in range(1, len(distances.flatten())):\n",
    "        business_id = user_item_matrix.columns[indices.flatten()[i]]\n",
    "        recommendations.append(business_id)\n",
    "    return recommendations\n",
    "\n",
    "# Ejemplo de uso\n",
    "user_to_recommend = 1\n",
    "recommended_businesses = get_recommendations(user_to_recommend)\n",
    "\n",
    "print(f\"Recomendaciones para el usuario {user_to_recommend}: {recommended_businesses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '6Mhbp06FEhD9uxUGCCUmKA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Ajustar el modelo a las características\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py:178\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    160\u001b[0m )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:498\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 498\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:1998\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   1997\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1998\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2000\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2001\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2002\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2003\u001b[0m     ):\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2006\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2007\u001b[0m         ):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '6Mhbp06FEhD9uxUGCCUmKA'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Seleccionar características relevantes para el modelo\n",
    "features = df_ml[['user_id', 'business_id', 'review_stars']]\n",
    "\n",
    "# Inicializar el modelo NearestNeighbors\n",
    "model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "\n",
    "# Ajustar el modelo a las características\n",
    "model.fit(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Ajustar el modelo a las características\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Ejemplo de hacer una recomendación para un usuario específico\u001b[39;00m\n\u001b[0;32m     34\u001b[0m user_id_to_predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser1\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py:178\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    160\u001b[0m )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:498\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 498\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:440\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[1;32m--> 440\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[1;32mc:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2021\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[0;32m   2020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[1;32m-> 2021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m     )\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {'user_id': ['user1', 'user1', 'user2', 'user2', 'user3'],\n",
    "        'business_id': ['business101', 'business102', 'business101', 'business103', 'business104'],\n",
    "        'review_stars': [5, 4, 5, 3, 4],\n",
    "        'cat_elite': [1, 0, 1, 0, 1],\n",
    "        'cat_limpieza': [1, 1, 0, 1, 1],\n",
    "        'cat_ambiente': [0, 1, 1, 1, 0],\n",
    "        'cat_promociones': [1, 0, 1, 0, 1],\n",
    "        'cat_extra': [0, 1, 1, 0, 0]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Seleccionar características relevantes para el modelo\n",
    "features = df[['user_id', 'business_id', 'review_stars', 'cat_elite', 'cat_limpieza', 'cat_ambiente', 'cat_promociones', 'cat_extra']]\n",
    "\n",
    "# Convertir las columnas 'user_id' y 'business_id' a representaciones numéricas\n",
    "vectorizer = CountVectorizer()\n",
    "user_business_matrix = vectorizer.fit_transform(features[['user_id', 'business_id']].apply(lambda x: ' '.join(x), axis=1))\n",
    "\n",
    "# Concatenar las representaciones numéricas con las demás características\n",
    "features_numeric = pd.concat([features.drop(['user_id', 'business_id'], axis=1), pd.DataFrame(user_business_matrix.toarray())], axis=1)\n",
    "\n",
    "# Inicializar el modelo NearestNeighbors\n",
    "model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "\n",
    "# Ajustar el modelo a las características\n",
    "model.fit(features_numeric)\n",
    "\n",
    "# Ejemplo de hacer una recomendación para un usuario específico\n",
    "user_id_to_predict = 'user1'\n",
    "business_id_to_predict = 'business102'\n",
    "user_to_predict = features_numeric[features['user_id'] == user_id_to_predict].iloc[0].values.reshape(1, -1)\n",
    "\n",
    "# Encontrar los vecinos más cercanos\n",
    "distances, indices = model.kneighbors(user_to_predict)\n",
    "\n",
    "# Obtener las recomendaciones basadas en los vecinos más cercanos\n",
    "recommended_business_ids = features_numeric.iloc[indices[0]]['business_id'].tolist()\n",
    "\n",
    "print(f\"Recomendaciones para el usuario {user_id_to_predict}: {recommended_business_ids}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
